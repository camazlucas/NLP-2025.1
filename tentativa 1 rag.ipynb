{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20d5748",
   "metadata": {},
   "source": [
    "# Carregando Pacotes e Ajustando a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27a8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c982b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Dispositivo: GPU\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"üîß Dispositivo: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a65891",
   "metadata": {},
   "source": [
    "# Variaveis Globais ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f3da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELO_EXTRATIVO = \"pierreguillou/bert-large-cased-squad-v1.1-portuguese\"\n",
    "MODELO_SEMANTICO = \"neuralmind/bert-base-portuguese-cased\"\n",
    "MODELO_GERATIVO = \"facebook/bart-base\"  # Modelo leve e est√°vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05dc8759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Carregando modelos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No sentence-transformers model found with name neuralmind/bert-base-portuguese-cased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelos carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 3. Carregamento √† Prova de Erros\n",
    "try:\n",
    "    print(\"‚è≥ Carregando modelos...\")\n",
    "    \n",
    "    # Extrativo (seu modelo original)\n",
    "    qa_pipeline = pipeline(\n",
    "        \"question-answering\",\n",
    "        model=MODELO_EXTRATIVO,\n",
    "        tokenizer=MODELO_EXTRATIVO,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Sem√¢ntico (para busca)\n",
    "    model_embed = SentenceTransformer(MODELO_SEMANTICO)\n",
    "    \n",
    "    # Generativo (alternativa est√°vel)\n",
    "    tokenizer_gen = AutoTokenizer.from_pretrained(MODELO_GERATIVO)\n",
    "    model_gen = AutoModel.from_pretrained(MODELO_GERATIVO).to(device)\n",
    "    \n",
    "    print(\"‚úÖ Modelos carregados com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Falha cr√≠tica: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8fe07b",
   "metadata": {},
   "source": [
    "# Fun√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406e0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_documento(caminho):\n",
    "    \"\"\"Mantido igual ao seu original\"\"\"\n",
    "    with pdfplumber.open(caminho) as pdf:\n",
    "        return \" \".join(page.extract_text() for page in pdf.pages if page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d292e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_texto(texto, tamanho=400, sobreposicao=100):\n",
    "    \"\"\"Vers√£o otimizada da sua fun√ß√£o\"\"\"\n",
    "    palavras = texto.split()\n",
    "    return [\n",
    "        \" \".join(palavras[i:i + tamanho])\n",
    "        for i in range(0, len(palavras), tamanho - sobreposicao)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb97ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_trechos(pergunta, trechos, top_k=3):\n",
    "    \"\"\"Busca sem√¢ntica simplificada\"\"\"\n",
    "    emb_pergunta = model_embed.encode(pergunta)\n",
    "    emb_trechos = model_embed.encode(trechos)\n",
    "    simil = cosine_similarity([emb_pergunta], emb_trechos)[0]\n",
    "    return [trechos[i] for i in np.argsort(simil)[-top_k:][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a94e2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder(pergunta, contexto):\n",
    "    \"\"\"Resposta direta sem gerador complexo\"\"\"\n",
    "    resultado = qa_pipeline(question=pergunta, context=contexto)\n",
    "    return {\n",
    "        \"resposta\": resultado[\"answer\"],\n",
    "        \"score\": resultado[\"score\"],\n",
    "        \"contexto\": contexto[:200] + \"...\"  # Preview\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f981a",
   "metadata": {},
   "source": [
    "# Processando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ea749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Processando documento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìÑ Processando documento...\")\n",
    "texto = carregar_documento(\"cabelos cacheados.pdf\")\n",
    "trechos = dividir_texto(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98c8fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"Quantos s√£o os tipos de cabelos cacheados?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c89b16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantes = buscar_trechos(pergunta, trechos)\n",
    "melhor = responder(pergunta, \" \".join(relevantes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa4432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Resposta (score: 0.43):\n",
      "Tipo 2 (ondulado), Tipo 3\n",
      "\n",
      "üìå Contexto: Defini√ß√£o e Tipos de Cachos Cabelos cacheados s√£o caracterizados por sua estrutura em espiral ou ondulada, resultante de fol√≠culos pilosos assim√©tricos. Essa forma se deve √† distribui√ß√£o desigual de q...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüí° Resposta (score: {melhor['score']:.2f}):\")\n",
    "print(melhor[\"resposta\"])\n",
    "print(f\"\\nüìå Contexto: {melhor['contexto']}\\n\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rocm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
