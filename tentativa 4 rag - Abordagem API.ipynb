{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6fb944",
   "metadata": {},
   "source": [
    "# Carregando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a255f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import pdfplumber\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290d7430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Rodando em: GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Verifica e configura o dispositivo (GPU/CPU)\n",
    "device = 0 if torch.cuda.is_available() else -1  # 0 = GPU, -1 = CPU\n",
    "print(f\"üîß Rodando em: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da93f3",
   "metadata": {},
   "source": [
    "# Vari√°veis Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ef9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamanho da Janela de Contexto\n",
    "window_size=400\n",
    "\n",
    "#Overlap da Janela de Contexto\n",
    "stride=100\n",
    "\n",
    "#Tamanho da Chunk\n",
    "chunk_size = 400\n",
    "    \n",
    "#Overlap da Chunk\n",
    "overlap = 100\n",
    "\n",
    "#Tamanho M√°ximo da Pergunta\n",
    "tamanho_pergunta = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575006b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_tokenizador = \"pierreguillou/bert-large-cased-squad-v1.1-portuguese\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f1b043",
   "metadata": {},
   "source": [
    "# Tratamento do Documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "964af42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Carregar modelo BERTimbau pr√©-treinado para Q&A em Portugues\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_tokenizador)\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model= modelo_tokenizador,  # Modelo em Portugues\n",
    "    tokenizer=modelo_tokenizador,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286ebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_documento(caminho_do_pdf):\n",
    "\n",
    "    with pdfplumber.open(caminho_do_pdf) as pdf:\n",
    "        texto = \" \".join(\n",
    "            page.extract_text() for page in pdf.pages \n",
    "            if page.extract_text()  # Ignora p√°ginas sem texto\n",
    "        )\n",
    "        texto = \" \".join(texto.split())  # Normaliza espa√ßos\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67c08d",
   "metadata": {},
   "source": [
    "## Divisao em Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7c80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_em_chunks_tokenizados(texto):\n",
    "\n",
    "    tokens = tokenizer.tokenize(texto)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        chunks.append(tokenizer.convert_tokens_to_string(chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b9cdc",
   "metadata": {},
   "source": [
    "## Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4113e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_tokenizados(texto):\n",
    "    tokens = tokenizer.tokenize(texto)\n",
    "    janelas = []\n",
    "    \n",
    "    for i in range(0, len(tokens), stride):\n",
    "        janela = tokens[i:i + window_size]\n",
    "        texto_janela = tokenizer.convert_tokens_to_string(janela)\n",
    "        janelas.append(texto_janela)\n",
    "        \n",
    "        # Para se chegarmos ao final do texto\n",
    "        if i + window_size >= len(tokens):\n",
    "            break\n",
    "    \n",
    "    return janelas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc972ced",
   "metadata": {},
   "source": [
    "## Selecionar Divis√£o do Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a208a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisao em Janela Deslizante\n",
    "\n",
    "divisao_do_texto = sliding_window_tokenizados(documento)\n",
    "\n",
    "#Divisao em Chunks\n",
    "\n",
    "#divisao_do_texto = dividir_em_chunks_tokenizados(documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ddc6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "documento = carregar_documento('Cabelo Cacheado Maior.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067f817",
   "metadata": {},
   "source": [
    "# Tokeniza√ß√£o dos Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eec14aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_vetorizador = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Vetorizar todos os chunks\n",
    "vetores = modelo_vetorizador.encode(divisao_do_texto, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43e90d",
   "metadata": {},
   "source": [
    "# Fun√ß√£o Recupera√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d86bc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_chunks(pergunta, modelo_vetorizador, divisao_do_texto, k=3):\n",
    "    # Vetoriza a pergunta\n",
    "    vetor_pergunta = modelo_vetorizador.encode([pergunta], convert_to_tensor=False)\n",
    "    \n",
    "    # Vetoriza todos os chunks\n",
    "    vetores_chunks = modelo_vetorizador.encode(divisao_do_texto, convert_to_tensor=False)\n",
    "    \n",
    "    # Calcula similaridade\n",
    "    sim = cosine_similarity(vetor_pergunta, vetores_chunks)\n",
    "    \n",
    "    # Pega √≠ndices dos top-k chunks mais similares\n",
    "    top_k_indices = np.argsort(sim[0])[::-1][:k]\n",
    "    \n",
    "    chunks_relevantes = [divisao_do_texto[i] for i in top_k_indices]\n",
    "    \n",
    "    return chunks_relevantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e6154",
   "metadata": {},
   "source": [
    "# Modelo Gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd2569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09711479732f459d9717f8d14481e73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e385dd820f234a7c94a32cbef14c68c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fe6fa16ba34aeba135e8f5bc01a85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_gerador = pipeline(\"text2text-generation\", model=\"facebook/bart-large\", device=device)\n",
    "\n",
    "def gerar_resposta(pergunta, chunks_relevantes):\n",
    "    contexto = \" \".join(chunks_relevantes)\n",
    "    prompt = f\"Contexto: {contexto} \\n\\nPergunta: {pergunta} \\n\\nResposta:\"\n",
    "    resposta = modelo_gerador(prompt, max_length=200)\n",
    "    return resposta[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ea963",
   "metadata": {},
   "source": [
    "# Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88089d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Resposta: Os cabelos do Tipo 2, por exemplo, so considerados ondulados, transitando entre o liso e o cacheado\n"
     ]
    }
   ],
   "source": [
    "pergunta = \"Quais s√£o os tipos de cachos?\"\n",
    "\n",
    "chunks_relevantes = recuperar_chunks(pergunta, modelo_vetorizador, divisao_do_texto)\n",
    "\n",
    "resposta = gerar_resposta(pergunta, chunks_relevantes)\n",
    "\n",
    "print(\"üìù Resposta:\", resposta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rocm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
